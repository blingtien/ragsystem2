#!/usr/bin/env python3
"""
PDF Parser Performance Test
å®é™…æµ‹è¯•MinerU vs Doclingåœ¨ä¸åŒå¤§å°PDFæ–‡ä»¶ä¸Šçš„æ€§èƒ½
"""

import asyncio
import time
import tempfile
import os
import psutil
from pathlib import Path
from typing import Dict, List
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PerformanceTestSuite:
    """PDFè§£æå™¨æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.results = []
        self.test_files = []
    
    def create_test_pdf(self, size_mb: int) -> Path:
        """åˆ›å»ºæŒ‡å®šå¤§å°çš„æµ‹è¯•PDFæ–‡ä»¶"""
        # è¿™é‡Œåº”è¯¥åˆ›å»ºçœŸå®çš„PDFæ–‡ä»¶ç”¨äºæµ‹è¯•
        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå ä½ç¬¦
        temp_dir = Path(tempfile.mkdtemp())
        test_file = temp_dir / f"test_{size_mb}mb.pdf"
        
        # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹ŸPDFæ–‡ä»¶ï¼ˆå®é™…åº”è¯¥æ˜¯çœŸå®PDFï¼‰
        with open(test_file, 'wb') as f:
            # å†™å…¥æ¨¡æ‹Ÿå†…å®¹è¾¾åˆ°æŒ‡å®šå¤§å°
            content = b"PDF_simulation_content" * (size_mb * 1024 * 1024 // 30)
            f.write(content)
        
        return test_file
    
    async def test_parser_performance(self, parser_name: str, file_path: Path) -> Dict:
        """æµ‹è¯•å•ä¸ªè§£æå™¨çš„æ€§èƒ½"""
        result = {
            "parser": parser_name,
            "file_path": str(file_path),
            "file_size_mb": file_path.stat().st_size / (1024 * 1024),
            "success": False,
            "processing_time": 0,
            "memory_usage_mb": 0,
            "error": None
        }
        
        try:
            # è®°å½•å¼€å§‹æ—¶çš„å†…å­˜ä½¿ç”¨
            process = psutil.Process()
            start_memory = process.memory_info().rss / (1024 * 1024)
            start_time = time.time()
            
            if parser_name == "mineru":
                await self._test_mineru_parser(file_path)
            elif parser_name == "docling":
                await self._test_docling_parser(file_path)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è§£æå™¨: {parser_name}")
            
            # è®°å½•ç»“æŸæ—¶é—´å’Œå†…å­˜
            end_time = time.time()
            end_memory = process.memory_info().rss / (1024 * 1024)
            
            result.update({
                "success": True,
                "processing_time": end_time - start_time,
                "memory_usage_mb": end_memory - start_memory
            })
            
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"{parser_name} è§£æå¤±è´¥: {e}")
        
        return result
    
    async def _test_mineru_parser(self, file_path: Path):
        """æµ‹è¯•MinerUè§£æå™¨"""
        try:
            from raganything.parser import MineruParser
            parser = MineruParser()
            
            # æ¨¡æ‹Ÿè§£æè¿‡ç¨‹
            if parser.check_installation():
                # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„è§£ææ–¹æ³•
                # result = parser.parse_pdf(file_path, output_dir="./test_output")
                # ä¸ºäº†æµ‹è¯•æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                logger.info(f"MinerU æˆåŠŸå¤„ç†: {file_path.name}")
            else:
                raise Exception("MinerU æœªæ­£ç¡®å®‰è£…")
                
        except ImportError:
            raise Exception("æ— æ³•å¯¼å…¥ MinerU")
    
    async def _test_docling_parser(self, file_path: Path):
        """æµ‹è¯•Doclingè§£æå™¨"""
        try:
            from raganything.parser import DoclingParser
            parser = DoclingParser()
            
            # æ¨¡æ‹Ÿè§£æè¿‡ç¨‹
            if parser.check_installation():
                # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„è§£ææ–¹æ³•
                # result = parser.parse_pdf(file_path, output_dir="./test_output")
                # ä¸ºäº†æµ‹è¯•æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                await asyncio.sleep(0.15)  # æ¨¡æ‹Ÿç¨é•¿çš„å¤„ç†æ—¶é—´
                logger.info(f"Docling æˆåŠŸå¤„ç†: {file_path.name}")
            else:
                raise Exception("Docling æœªæ­£ç¡®å®‰è£…")
                
        except ImportError:
            raise Exception("æ— æ³•å¯¼å…¥ Docling")
    
    async def run_comprehensive_test(self):
        """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•"""
        print("ğŸ§ª PDFè§£æå™¨æ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        
        # æµ‹è¯•ä¸åŒå¤§å°çš„æ–‡ä»¶
        test_sizes = [1, 5, 10, 50, 100]  # MB
        parsers = ["mineru", "docling"]
        
        for size_mb in test_sizes:
            print(f"\nğŸ“„ æµ‹è¯• {size_mb}MB PDFæ–‡ä»¶:")
            
            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            test_file = self.create_test_pdf(size_mb)
            self.test_files.append(test_file)
            
            parser_results = []
            
            for parser in parsers:
                print(f"   æµ‹è¯• {parser}...")
                result = await self.test_parser_performance(parser, test_file)
                parser_results.append(result)
                self.results.append(result)
                
                if result["success"]:
                    print(f"   âœ… {parser}: {result['processing_time']:.2f}s, {result['memory_usage_mb']:.1f}MBå†…å­˜")
                else:
                    print(f"   âŒ {parser}: {result['error']}")
            
            # æ¯”è¾ƒç»“æœ
            if len([r for r in parser_results if r["success"]]) >= 2:
                successful_results = [r for r in parser_results if r["success"]]
                fastest = min(successful_results, key=lambda x: x["processing_time"])
                least_memory = min(successful_results, key=lambda x: x["memory_usage_mb"])
                
                print(f"   ğŸ† æœ€å¿«: {fastest['parser']} ({fastest['processing_time']:.2f}s)")
                print(f"   ğŸ’¾ æœ€çœå†…å­˜: {least_memory['parser']} ({least_memory['memory_usage_mb']:.1f}MB)")
    
    def analyze_results(self):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•åˆ†æ")
        print("=" * 50)
        
        if not self.results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        # æŒ‰è§£æå™¨åˆ†ç»„
        by_parser = {}
        for result in self.results:
            parser = result["parser"]
            if parser not in by_parser:
                by_parser[parser] = []
            by_parser[parser].append(result)
        
        # è®¡ç®—å¹³å‡æ€§èƒ½
        for parser, results in by_parser.items():
            successful = [r for r in results if r["success"]]
            if successful:
                avg_time = sum(r["processing_time"] for r in successful) / len(successful)
                avg_memory = sum(r["memory_usage_mb"] for r in successful) / len(successful)
                success_rate = len(successful) / len(results) * 100
                
                print(f"\n{parser.upper()} è§£æå™¨:")
                print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
                print(f"   å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.2f}ç§’")
                print(f"   å¹³å‡å†…å­˜ä½¿ç”¨: {avg_memory:.1f}MB")
            else:
                print(f"\n{parser.upper()} è§£æå™¨:")
                print(f"   âŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥")
        
        # ç»™å‡ºå»ºè®®
        self.generate_recommendations()
    
    def generate_recommendations(self):
        """åŸºäºæµ‹è¯•ç»“æœç”Ÿæˆå»ºè®®"""
        print("\nğŸ’¡ åŸºäºæµ‹è¯•ç»“æœçš„å»ºè®®:")
        print("=" * 30)
        
        successful_results = [r for r in self.results if r["success"]]
        
        if not successful_results:
            print("âŒ æ— æ³•ç”Ÿæˆå»ºè®®ï¼Œæ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥")
            return
        
        # æŒ‰æ–‡ä»¶å¤§å°åˆ†æ
        small_files = [r for r in successful_results if r["file_size_mb"] <= 10]
        large_files = [r for r in successful_results if r["file_size_mb"] > 50]
        
        if small_files:
            fastest_small = min(small_files, key=lambda x: x["processing_time"])
            print(f"ğŸ“„ å°æ–‡ä»¶ (â‰¤10MB): æ¨è {fastest_small['parser']}")
        
        if large_files:
            fastest_large = min(large_files, key=lambda x: x["processing_time"])
            least_memory_large = min(large_files, key=lambda x: x["memory_usage_mb"])
            print(f"ğŸ“„ å¤§æ–‡ä»¶ (>50MB):")
            print(f"   é€Ÿåº¦ä¼˜å…ˆ: {fastest_large['parser']}")
            print(f"   å†…å­˜ä¼˜å…ˆ: {least_memory_large['parser']}")
        
        print("\nâš ï¸  æ³¨æ„: è¿™äº›ç»“æœåŸºäºæ¨¡æ‹Ÿæµ‹è¯•ï¼Œå®é™…æ€§èƒ½å¯èƒ½ä¸åŒ")
        print("   å»ºè®®ä½¿ç”¨çœŸå®PDFæ–‡ä»¶è¿›è¡Œæ›´å‡†ç¡®çš„æµ‹è¯•")
    
    def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
        for test_file in self.test_files:
            try:
                if test_file.exists():
                    test_file.unlink()
                    test_file.parent.rmdir()
            except Exception as e:
                logger.warning(f"æ¸…ç†æµ‹è¯•æ–‡ä»¶å¤±è´¥: {e}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    test_suite = PerformanceTestSuite()
    
    try:
        await test_suite.run_comprehensive_test()
        test_suite.analyze_results()
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        test_suite.cleanup()

if __name__ == "__main__":
    print("ğŸ“‹ æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºæ€§æµ‹è¯•è„šæœ¬")
    print("   å®é™…æ€§èƒ½æµ‹è¯•éœ€è¦çœŸå®çš„PDFæ–‡ä»¶å’Œå®Œæ•´çš„è§£æå™¨å®‰è£…")
    print("   å½“å‰ç»“æœä»…ç”¨äºå±•ç¤ºæµ‹è¯•æ¡†æ¶")
    print()
    
    asyncio.run(main())
"""
RAGç®¡ç†å™¨
å•ä¾‹æ¨¡å¼ç®¡ç†RAGå®ä¾‹ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨å’Œèµ„æºå¤ç”¨
"""
import asyncio
import os
import sys
from pathlib import Path
from typing import Optional
from threading import RLock

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„åˆ°sys.path
sys.path.append(str(Path(__file__).parent.parent.parent))

from lightrag.llm.openai import openai_complete_if_cache
from lightrag.utils import EmbeddingFunc, logger
from raganything import RAGAnything, RAGAnythingConfig
from simple_qwen_embed import qwen_embed

from config.settings import settings
from cache_enhanced_processor import CacheEnhancedProcessor
from cache_statistics import initialize_cache_tracking


class RAGManager:
    """
    RAGç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼ç®¡ç†RAGå®ä¾‹
    æä¾›çº¿ç¨‹å®‰å…¨çš„RAGå®ä¾‹è®¿é—®å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†
    """
    
    _instance = None
    _instance_lock = RLock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super(RAGManager, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        self._rag_instance: Optional[RAGAnything] = None
        self._cache_enhanced_processor: Optional[CacheEnhancedProcessor] = None
        self._initialization_lock = RLock()
        self._is_initializing = False
        self._initialized = True
    
    async def get_rag_instance(self) -> Optional[RAGAnything]:
        """
        è·å–RAGå®ä¾‹ï¼Œå¦‚æœæœªåˆå§‹åŒ–åˆ™è‡ªåŠ¨åˆå§‹åŒ–
        çº¿ç¨‹å®‰å…¨çš„æ‡’åŠ è½½æ¨¡å¼
        """
        if self._rag_instance is not None:
            return self._rag_instance
            
        with self._initialization_lock:
            if self._is_initializing:
                # å¦‚æœæ­£åœ¨åˆå§‹åŒ–ï¼Œç­‰å¾…å®Œæˆ
                while self._is_initializing:
                    await asyncio.sleep(0.1)
                return self._rag_instance
            
            if self._rag_instance is None:
                await self._initialize()
            
        return self._rag_instance
    
    async def _initialize(self) -> None:
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        self._is_initializing = True
        
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–RAGç³»ç»Ÿ...")
            
            # æ£€æŸ¥APIå¯†é’¥
            if not settings.deepseek_api_key:
                logger.error("æœªæ‰¾åˆ°DEEPSEEK_API_KEYï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡")
                return
            
            # åˆ›å»ºRAGAnythingé…ç½®
            config = RAGAnythingConfig(
                working_dir=settings.working_dir,
                parser_output_dir=settings.output_dir,
                parser=settings.parser,
                parse_method=settings.parse_method,
                enable_image_processing=settings.enable_image_processing,
                enable_table_processing=settings.enable_table_processing,
                enable_equation_processing=settings.enable_equation_processing,
            )
            
            # å®šä¹‰LLMå‡½æ•°
            def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
                return openai_complete_if_cache(
                    "deepseek-chat",
                    prompt,
                    system_prompt=system_prompt,
                    history_messages=history_messages,
                    api_key=settings.deepseek_api_key,
                    base_url=settings.llm_binding_host,
                    **kwargs,
                )
            
            # å®šä¹‰è§†è§‰æ¨¡å‹å‡½æ•°
            def vision_model_func(
                prompt,
                system_prompt=None,
                history_messages=[],
                image_data=None,
                messages=None,
                **kwargs,
            ):
                if messages:
                    return openai_complete_if_cache(
                        "deepseek-vl",
                        "",
                        system_prompt=None,
                        history_messages=[],
                        messages=messages,
                        api_key=settings.deepseek_api_key,
                        base_url=settings.llm_binding_host,
                        **kwargs,
                    )
                elif image_data:
                    return openai_complete_if_cache(
                        "deepseek-vl",
                        "",
                        system_prompt=None,
                        history_messages=[],
                        messages=[
                            {"role": "system", "content": system_prompt} if system_prompt else None,
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": prompt},
                                    {
                                        "type": "image_url",
                                        "image_url": {"url": f"data:image/jpeg;base64,{image_data}"},
                                    },
                                ],
                            } if image_data else {"role": "user", "content": prompt},
                        ],
                        api_key=settings.deepseek_api_key,
                        base_url=settings.llm_binding_host,
                        **kwargs,
                    )
                else:
                    return llm_model_func(prompt, system_prompt, history_messages, **kwargs)
            
            # å®šä¹‰åµŒå…¥å‡½æ•°
            embedding_func = EmbeddingFunc(
                embedding_dim=1024,
                max_token_size=512,
                func=qwen_embed,
            )
            
            # é…ç½®LightRAGç¼“å­˜è®¾ç½®
            lightrag_kwargs = {
                "enable_llm_cache": settings.enable_llm_cache,
            }
            
            # åˆå§‹åŒ–RAGAnything
            self._rag_instance = RAGAnything(
                config=config,
                llm_model_func=llm_model_func,
                vision_model_func=vision_model_func,
                embedding_func=embedding_func,
                lightrag_kwargs=lightrag_kwargs,
            )
            
            # ç¡®ä¿LightRAGå®ä¾‹å·²åˆå§‹åŒ–
            await self._rag_instance._ensure_lightrag_initialized()
            
            # åˆå§‹åŒ–ç¼“å­˜ç»Ÿè®¡è·Ÿè¸ª
            initialize_cache_tracking(settings.working_dir)
            
            # åˆ›å»ºç¼“å­˜å¢å¼ºå¤„ç†å™¨
            self._cache_enhanced_processor = CacheEnhancedProcessor(
                rag_instance=self._rag_instance,
                storage_dir=settings.working_dir
            )
            
            # è®°å½•åˆå§‹åŒ–ä¿¡æ¯
            logger.info("ğŸ¯ RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            logger.info("ğŸ“‹ ç³»ç»Ÿé…ç½®ä¿¡æ¯:")
            logger.info(f"   ğŸ“ æ•°æ®ç›®å½•: {settings.working_dir}")
            logger.info(f"   ğŸ“¤ è¾“å‡ºç›®å½•: {settings.output_dir}")
            logger.info(f"   ğŸ  RAGAnythingå·¥ä½œç›®å½•: {self._rag_instance.working_dir}")
            logger.info(f"   ğŸ¤– LLMæ¨¡å‹: DeepSeek API ({settings.llm_binding_host})")
            logger.info(f"   ğŸ”¤ åµŒå…¥æ¨¡å‹: æœ¬åœ°Qwen3-Embedding-0.6B")
            logger.info(f"   ğŸ’¾ ç¼“å­˜é…ç½®: Parse Cache={settings.enable_parse_cache}, LLM Cache={settings.enable_llm_cache}")
            
            # éªŒè¯ç›®å½•ä¸€è‡´æ€§
            if self._rag_instance.working_dir != settings.working_dir:
                logger.warning(f"âš ï¸ å·¥ä½œç›®å½•ä¸ä¸€è‡´! APIæœåŠ¡å™¨: {settings.working_dir}, RAGAnything: {self._rag_instance.working_dir}")
            else:
                logger.info("âœ… å·¥ä½œç›®å½•é…ç½®ä¸€è‡´")
                
            # æ˜¾ç¤ºå­˜å‚¨åç«¯ä¿¡æ¯
            storage_mode = getattr(settings, 'storage_mode', 'hybrid')
            logger.info(f"ğŸ—„ï¸ å­˜å‚¨æ¨¡å¼: {storage_mode}")
            if storage_mode in ['hybrid', 'postgres_only']:
                postgres_host = os.getenv('POSTGRES_HOST', 'localhost')
                postgres_db = os.getenv('POSTGRES_DB', 'raganything')
                logger.info(f"   ğŸ“Š PostgreSQL: {postgres_host}/{postgres_db}")
            if storage_mode in ['hybrid', 'neo4j_only']:
                neo4j_uri = os.getenv('NEO4J_URI', 'bolt://localhost:7687')
                logger.info(f"   ğŸ•¸ï¸ Neo4j: {neo4j_uri}")
                
        except Exception as e:
            logger.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self._rag_instance = None
            self._cache_enhanced_processor = None
            
        finally:
            self._is_initializing = False
    
    async def get_cache_enhanced_processor(self) -> Optional[CacheEnhancedProcessor]:
        """è·å–ç¼“å­˜å¢å¼ºå¤„ç†å™¨"""
        # ç¡®ä¿RAGå®ä¾‹å·²åˆå§‹åŒ–
        await self.get_rag_instance()
        return self._cache_enhanced_processor
    
    def is_ready(self) -> bool:
        """æ£€æŸ¥RAGæ˜¯å¦å°±ç»ª"""
        return self._rag_instance is not None and not self._is_initializing
    
    async def shutdown(self) -> None:
        """å…³é—­RAGç³»ç»Ÿï¼Œæ¸…ç†èµ„æº"""
        with self._initialization_lock:
            if self._rag_instance:
                try:
                    # è¿™é‡Œå¯ä»¥æ·»åŠ RAGå®ä¾‹çš„æ¸…ç†é€»è¾‘
                    logger.info("å…³é—­RAGç³»ç»Ÿ")
                    self._rag_instance = None
                    self._cache_enhanced_processor = None
                except Exception as e:
                    logger.error(f"å…³é—­RAGç³»ç»Ÿæ—¶å‡ºé”™: {str(e)}")
    
    async def health_check(self) -> dict:
        """å¥åº·æ£€æŸ¥"""
        is_ready = self.is_ready()
        rag_instance = await self.get_rag_instance()
        
        health_info = {
            "rag_ready": is_ready,
            "rag_instance_available": rag_instance is not None,
            "cache_processor_available": self._cache_enhanced_processor is not None,
            "working_directory": settings.working_dir,
            "output_directory": settings.output_dir,
            "device_type": settings.device_type,
            "torch_available": settings.torch_available
        }
        
        if rag_instance:
            try:
                # å¯ä»¥æ·»åŠ æ›´å¤šçš„å¥åº·æ£€æŸ¥é€»è¾‘
                health_info["lightrag_initialized"] = hasattr(rag_instance, 'lightrag') and rag_instance.lightrag is not None
            except Exception as e:
                health_info["health_check_error"] = str(e)
        
        return health_info
    
    async def reload(self) -> bool:
        """é‡æ–°åŠ è½½RAGå®ä¾‹"""
        try:
            logger.info("é‡æ–°åŠ è½½RAGç³»ç»Ÿ")
            await self.shutdown()
            await self._initialize()
            return self.is_ready()
        except Exception as e:
            logger.error(f"é‡æ–°åŠ è½½RAGç³»ç»Ÿå¤±è´¥: {str(e)}")
            return False


# åˆ›å»ºå…¨å±€RAGç®¡ç†å™¨å®ä¾‹
_rag_manager_instance = None

def get_rag_manager() -> RAGManager:
    """è·å–RAGç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _rag_manager_instance
    if _rag_manager_instance is None:
        _rag_manager_instance = RAGManager()
    return _rag_manager_instance